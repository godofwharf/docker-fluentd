<source>
  type tail
  path /var/lib/docker/containers/*/*-json.log
  pos_file /var/log/td-agent/fluentd-es-containers.log.pos
  time_format %Y-%m-%dT%H:%M:%S
  tag docker.*
  format json
  read_from_head false
  rotate_wait 30
  keep_time_key true
</source>

<filter docker.var.lib.docker.containers.*.*.log>
 type grep
 regexp1 "#{ENV['LOG_PATTERN']}"
</filter>

# Using filter to add hostname and container IDs to each event
<filter docker.var.lib.docker.containers.*.*.log>
  type record_transformer
  enable_ruby
  <record>
    app_id ${log.split(' ')[0].split('-')[1..-1].join('-')}
    hostname "#{ENV['HOST']}"
    time ${require 'date';(((DateTime.parse(time.to_s))).to_time.utc + 330 * 60).strftime('%Y-%m-%dT%H:%M:%S+05:30')}
  </record>
</filter>

<match docker.var.lib.docker.containers.*.*.log>
  @type                 kafka_buffered
  # Brokers: you can choose either brokers or zookeeper.
  brokers               "#{ENV['KAFKA_BROKER']}"
  default_topic         "#{ENV['KAFKA_TOPIC']}"
  default_partition_key "#{ENV['KAFKA_PARTITION_KEY']}"
  output_data_type      json
  output_include_tag    false
  output_include_time   false
  max_send_retries      3
  required_acks         0
  ack_timeout_ms        1000
  compression_codec     gzip
  buffer_type           memory
  buffer_chunk_limit    "#{ENV['BUFFER_CHUNK_LIMIT']}"
  buffer_queue_limit    "#{ENV['BUFFER_QUEUE_LIMIT']}"
  flush_interval        15s
  max_retry_wait        60
  flush_at_shutdown     true
  disable_retry_limit   false
  retry_wait            1s
  retry_limit           8
</match>
